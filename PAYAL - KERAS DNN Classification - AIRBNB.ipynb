{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 - KERAS DNN Classification\n",
    "\n",
    "We will predict the price category, among 4 categories, of an AIRBNB listing (`price_category` column). This is a multi-class classification task.\n",
    "\n",
    "**The unit of analysis is an AIRBNB LISTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>price_per_extra_person</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_days_btw_first_last_review</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>price</th>\n",
       "      <th>price_gte_150</th>\n",
       "      <th>price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.282619</td>\n",
       "      <td>-71.133068</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moderate</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.286241</td>\n",
       "      <td>-71.134374</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>804</td>\n",
       "      <td>94.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_$75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.292438</td>\n",
       "      <td>-71.135765</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>2574</td>\n",
       "      <td>98.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_$75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.281106</td>\n",
       "      <td>-71.121021</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_$75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.284512</td>\n",
       "      <td>-71.136258</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>380</td>\n",
       "      <td>99.0</td>\n",
       "      <td>flexible</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>btw_$75-$150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_is_superhost  host_identity_verified neighbourhood_cleansed  \\\n",
       "0                  0                       0             Roslindale   \n",
       "1                  0                       1             Roslindale   \n",
       "2                  1                       1             Roslindale   \n",
       "3                  0                       0             Roslindale   \n",
       "4                  1                       1             Roslindale   \n",
       "\n",
       "    latitude  longitude property_type        room_type  accommodates  \\\n",
       "0  42.282619 -71.133068         House  Entire home/apt             4   \n",
       "1  42.286241 -71.134374     Apartment     Private room             2   \n",
       "2  42.292438 -71.135765     Apartment     Private room             2   \n",
       "3  42.281106 -71.121021         House     Private room             4   \n",
       "4  42.284512 -71.136258         House     Private room             2   \n",
       "\n",
       "   bathrooms  bedrooms  ...  guests_included price_per_extra_person  \\\n",
       "0        1.5       2.0  ...                1                      0   \n",
       "1        1.0       1.0  ...                0                      0   \n",
       "2        1.0       1.0  ...                1                     20   \n",
       "3        1.0       1.0  ...                2                     25   \n",
       "4        1.5       1.0  ...                1                      0   \n",
       "\n",
       "   minimum_nights  number_of_reviews  number_days_btw_first_last_review  \\\n",
       "0               2                  0                                  0   \n",
       "1               2                 36                                804   \n",
       "2               3                 41                               2574   \n",
       "3               1                  1                                  0   \n",
       "4               2                 29                                380   \n",
       "\n",
       "   review_scores_rating  cancellation_policy  price  price_gte_150  \\\n",
       "0                   NaN             moderate    250              1   \n",
       "1                  94.0             moderate     65              0   \n",
       "2                  98.0             moderate     65              0   \n",
       "3                 100.0             moderate     75              0   \n",
       "4                  99.0             flexible     79              0   \n",
       "\n",
       "  price_category  \n",
       "0        gte_226  \n",
       "1        lte_$75  \n",
       "2        lte_$75  \n",
       "3        lte_$75  \n",
       "4   btw_$75-$150  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"price_gte_150\" value in the data set:\n",
    "\n",
    "airbnb = pd.read_csv(\"airbnb.csv\")\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(airbnb, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be careful: we haven't seperated the target column yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the variables we can't use in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't use the following columns in this tutorial\n",
    "\n",
    "train = train_set.drop(['price', 'price_gte_150'], axis=1)\n",
    "test = test_set.drop(['price', 'price_gte_150'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable (we don't want to transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train[['price_category']]\n",
    "test_target = test[['price_category']]\n",
    "\n",
    "train_inputs = train.drop(['price_category'], axis=1)\n",
    "test_inputs = test.drop(['price_category'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Let's derive a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember, the \"minimum_nights\" column is highly skewed. Let's try to transform it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      1017\n",
       "2       666\n",
       "3       443\n",
       "4        88\n",
       "7        82\n",
       "5        58\n",
       "10       45\n",
       "30       18\n",
       "14       16\n",
       "15       14\n",
       "6        12\n",
       "28        6\n",
       "20        5\n",
       "32        3\n",
       "60        3\n",
       "9         2\n",
       "18        1\n",
       "13        1\n",
       "8         1\n",
       "273       1\n",
       "11        1\n",
       "21        1\n",
       "90        1\n",
       "23        1\n",
       "17        1\n",
       "25        1\n",
       "Name: minimum_nights, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs['minimum_nights'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_inputs['minimum_nights'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import power transformer from sklearn. It will help us create a \"normal distribution\"\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "PT = PowerTransformer(method = 'yeo-johnson', standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_min_nights = PT.fit_transform(train_inputs[['minimum_nights']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': '0'}>]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_min_nights).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE1: We didn't make the transformed variable as part of the input variables yet. To do that, we will use the pipeline.\n",
    "\n",
    "NOTE2: We don't need to create a function (like before). This transformer already has fit() and transform(). So, we can use this in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_is_superhost                      int64\n",
       "host_identity_verified                 int64\n",
       "neighbourhood_cleansed                object\n",
       "latitude                             float64\n",
       "longitude                            float64\n",
       "property_type                         object\n",
       "room_type                             object\n",
       "accommodates                           int64\n",
       "bathrooms                            float64\n",
       "bedrooms                             float64\n",
       "beds                                 float64\n",
       "bed_type                              object\n",
       "Number of amenities                    int64\n",
       "guests_included                        int64\n",
       "price_per_extra_person                 int64\n",
       "minimum_nights                         int64\n",
       "number_of_reviews                      int64\n",
       "number_days_btw_first_last_review      int64\n",
       "review_scores_rating                 float64\n",
       "cancellation_policy                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this stage, you can manually identify numeric, binary, and categorical columns as follows:**\n",
    "\n",
    "`numeric_columns = ['latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'Number of amenities', 'guests_included', 'price_per_extra_person', 'minimum_nights', 'number_of_reviews', 'number_days_btw_first_last_review', 'review_scores_rating']`\n",
    " \n",
    " `binary_columns = ['host_is_superhost', 'host_identity_verified']`\n",
    " \n",
    " `categorical_columns = ['neighbourhood_cleansed', 'property_type', 'room_type', 'bed_type', 'cancellation_policy']`\n",
    " \n",
    "<br>\n",
    " \n",
    "**If you do not want to manually type these, you can do the below tricks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['host_is_superhost', 'host_identity_verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost', 'host_identity_verified']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'Number of amenities',\n",
       " 'guests_included',\n",
       " 'price_per_extra_person',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'number_days_btw_first_last_review',\n",
       " 'review_scores_rating']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neighbourhood_cleansed',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'bed_type',\n",
       " 'cancellation_policy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = ['minimum_nights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_column = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('powertransformer', PowerTransformer(method = 'yeo-johnson', standardize=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns),\n",
    "        ('trans', my_new_column, transformed_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82254842,  0.69215829,  0.54753414, ...,  1.        ,\n",
       "         1.        ,  0.22348218],\n",
       "       [ 0.55146572,  0.15729058,  0.54753414, ...,  0.        ,\n",
       "         1.        ,  0.22348218],\n",
       "       [ 0.07311286, -1.97951247, -0.59100739, ...,  0.        ,\n",
       "         0.        ,  1.39051005],\n",
       "       ...,\n",
       "       [-0.61093878, -0.07631528,  3.96315871, ...,  0.        ,\n",
       "         1.        , -1.07759248],\n",
       "       [ 1.17819153, -0.94575177, -1.16027815, ...,  0.        ,\n",
       "         0.        , -1.07759248],\n",
       "       [-0.33618088,  1.03587419, -0.59100739, ...,  0.        ,\n",
       "         1.        ,  0.22348218]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488, 67)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.21269719, -1.20324989,  0.54753414, ...,  0.        ,\n",
       "         1.        ,  0.22348218],\n",
       "       [-2.86419979, -2.67831359, -0.59100739, ...,  0.        ,\n",
       "         0.        , -1.07759248],\n",
       "       [-0.11443035,  1.26295963, -0.59100739, ...,  0.        ,\n",
       "         1.        , -1.07759248],\n",
       "       ...,\n",
       "       [ 0.47803436, -1.63486781, -0.59100739, ...,  1.        ,\n",
       "         1.        , -1.07759248],\n",
       "       [ 0.59928397,  0.34795157,  2.82461719, ...,  0.        ,\n",
       "         0.        ,  0.22348218],\n",
       "       [ 0.19953968,  0.22845713, -0.59100739, ...,  0.        ,\n",
       "         1.        ,  1.65188006]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067, 67)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras needs Ordinal target values for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>btw_$151-$225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>lte_$75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>lte_$75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>btw_$75-$150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>btw_$75-$150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>btw_$75-$150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>btw_$75-$150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2488 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price_category\n",
       "1965        gte_226\n",
       "1450  btw_$151-$225\n",
       "2503        lte_$75\n",
       "944         lte_$75\n",
       "199    btw_$75-$150\n",
       "...             ...\n",
       "1130   btw_$75-$150\n",
       "1294        gte_226\n",
       "860         gte_226\n",
       "3507   btw_$75-$150\n",
       "3174   btw_$75-$150\n",
       "\n",
       "[2488 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       ...,\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "train_y = ord_enc.fit_transform(train_target)\n",
    "\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = ord_enc.transform(test_target)\n",
    "\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.3311897106109325\n"
     ]
    }
   ],
   "source": [
    "#Baseline Train Accuracy\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_y, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.3402061855670103\n"
     ]
    }
   ],
   "source": [
    "#Baseline Test Accuracy\n",
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_y, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification using Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If you don't have tensorflow installed, you need to convert this cell to \"code\" and execute it\n",
    "\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "# random seed do not work, so below dont work\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488, 67)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is your input shape?\n",
    "#(meaning: how many neurons should be in the input layer?)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer (Shallow) Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(67,))) # match the columns # train_x.shape[1] see above cell replace instead of 67\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='softmax')) # as it is multiclass and 4 target nuerons, as there are 4 categories\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,400</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             â”‚         \u001b[38;5;34m3,400\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              â”‚           \u001b[38;5;34m204\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,604</span> (14.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,604\u001b[0m (14.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,604</span> (14.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,604\u001b[0m (14.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal target (as in this example):\n",
    "\n",
    "Final layer's activation = **softmax** <br>\n",
    "loss = **sparse_categorical_crossentropy**\n",
    "\n",
    "## Binary target \n",
    "\n",
    "Final layer has only 1 neuron <br>\n",
    "Final layer's activation = **sigmoid** <br>\n",
    "loss = **binary_crossentropy**\n",
    "\n",
    "## One-hot target (rare cases)\n",
    "\n",
    "Final layer's activation = **softmax** <br>\n",
    "loss = **categorical_crossentropy**\n",
    "\n",
    "## Regression task (target is continuous)\n",
    "\n",
    "Final layer has only 1 neuron (keras.layers.Dense(1))<br>\n",
    "Activation is None<br>\n",
    "loss = **mean_squared_error**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.4180 - loss: 1.2190 - val_accuracy: 0.5989 - val_loss: 0.8709\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5952 - loss: 0.8937 - val_accuracy: 0.6270 - val_loss: 0.8187\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6302 - loss: 0.8274 - val_accuracy: 0.6401 - val_loss: 0.8028\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6527 - loss: 0.7909 - val_accuracy: 0.6382 - val_loss: 0.7983\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6657 - loss: 0.7615 - val_accuracy: 0.6495 - val_loss: 0.7965\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6789 - loss: 0.7315 - val_accuracy: 0.6495 - val_loss: 0.8008\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6920 - loss: 0.7051 - val_accuracy: 0.6467 - val_loss: 0.8044\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7081 - loss: 0.6770 - val_accuracy: 0.6467 - val_loss: 0.8153\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 0.6526 - val_accuracy: 0.6457 - val_loss: 0.8230\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7363 - loss: 0.6298 - val_accuracy: 0.6457 - val_loss: 0.8369\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7511 - loss: 0.6052 - val_accuracy: 0.6457 - val_loss: 0.8535\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7563 - loss: 0.5838 - val_accuracy: 0.6373 - val_loss: 0.8714\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7635 - loss: 0.5646 - val_accuracy: 0.6420 - val_loss: 0.8904\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7719 - loss: 0.5466 - val_accuracy: 0.6410 - val_loss: 0.9108\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7791 - loss: 0.5291 - val_accuracy: 0.6420 - val_loss: 0.9310\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7859 - loss: 0.5176 - val_accuracy: 0.6298 - val_loss: 0.9493\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7963 - loss: 0.5018 - val_accuracy: 0.6317 - val_loss: 0.9659\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8020 - loss: 0.4884 - val_accuracy: 0.6242 - val_loss: 0.9920\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8089 - loss: 0.4778 - val_accuracy: 0.6279 - val_loss: 1.0137\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8097 - loss: 0.4654 - val_accuracy: 0.6307 - val_loss: 1.0336\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=100)# 2500 rows will split into 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4375588893890381, 0.8291800618171692]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.44\n",
      "Train compile_metrics: 82.92%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "# the loss it does not have any meaning\n",
    "\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0292726755142212, 0.6307404041290283]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.03\n",
      "Test compile_metrics: 63.07%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "# the loss it does not have any meaning\n",
    "\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## have to apply regularization as the above is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Network (Pipe Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "# Pipe archietecture\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(67,)))\n",
    "model.add(keras.layers.Dense(67, activation='relu'))\n",
    "model.add(keras.layers.Dense(67, activation='relu'))\n",
    "model.add(keras.layers.Dense(67, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.4260 - loss: 1.1754 - val_accuracy: 0.6129 - val_loss: 0.8601\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5651 - loss: 0.9054 - val_accuracy: 0.6120 - val_loss: 0.8582\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5961 - loss: 0.8576 - val_accuracy: 0.6204 - val_loss: 0.8364\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6314 - loss: 0.8051 - val_accuracy: 0.6317 - val_loss: 0.8278\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6723 - loss: 0.7458 - val_accuracy: 0.6457 - val_loss: 0.8279\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6867 - loss: 0.6893 - val_accuracy: 0.6429 - val_loss: 0.8674\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7150 - loss: 0.6468 - val_accuracy: 0.6336 - val_loss: 0.9471\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7389 - loss: 0.5990 - val_accuracy: 0.6120 - val_loss: 0.9906\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7354 - loss: 0.5838 - val_accuracy: 0.6204 - val_loss: 1.0389\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7489 - loss: 0.5512 - val_accuracy: 0.6120 - val_loss: 1.0505\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7729 - loss: 0.5140 - val_accuracy: 0.6101 - val_loss: 1.1230\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7698 - loss: 0.5284 - val_accuracy: 0.6092 - val_loss: 1.2364\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7658 - loss: 0.5471 - val_accuracy: 0.6223 - val_loss: 1.1749\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7994 - loss: 0.4772 - val_accuracy: 0.5942 - val_loss: 1.1515\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8208 - loss: 0.4342 - val_accuracy: 0.6045 - val_loss: 1.2891\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8338 - loss: 0.3898 - val_accuracy: 0.5989 - val_loss: 1.4591\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8318 - loss: 0.3823 - val_accuracy: 0.6195 - val_loss: 1.4916\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.3741 - val_accuracy: 0.6111 - val_loss: 1.3561\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8411 - loss: 0.3853 - val_accuracy: 0.6307 - val_loss: 1.3973\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8588 - loss: 0.3539 - val_accuracy: 0.6101 - val_loss: 1.4634\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29174214601516724, 0.875]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.29\n",
      "Train compile_metrics: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4540643692016602, 0.6101218461990356]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.45\n",
      "Test compile_metrics: 61.01%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional layers above made it worse as it made model overfit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide & Deep Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's send all inputs to the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "\n",
    "inputlayer = keras.layers.Input(shape=(67,))\n",
    "\n",
    "hidden1 = keras.layers.Dense(67, activation='relu')(inputlayer)\n",
    "hidden2 = keras.layers.Dense(67, activation='relu')(hidden1)\n",
    "hidden3 = keras.layers.Dense(67, activation='relu')(hidden2)\n",
    "\n",
    "concat = keras.layers.Concatenate()([inputlayer, hidden3]) # Concatenate with input above that is stack this layer has 134 neurons\n",
    "# logic is taking advantage of nueral network and another model say regression, where you can advanatage of learnings of linear and non linear\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n",
    "output = keras.layers.Dense(4, activation='softmax')(concat)\n",
    "\n",
    "model = keras.Model(inputs =[inputlayer], outputs = output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_7       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,556</span> â”‚ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,556</span> â”‚ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,556</span> â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">134</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">540</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_7       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        â”‚      \u001b[38;5;34m4,556\u001b[0m â”‚ input_layer_7[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        â”‚      \u001b[38;5;34m4,556\u001b[0m â”‚ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        â”‚      \u001b[38;5;34m4,556\u001b[0m â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m134\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_7[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         â”‚        \u001b[38;5;34m540\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,208</span> (55.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,208\u001b[0m (55.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,208</span> (55.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,208\u001b[0m (55.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4533 - loss: 1.1550 - val_accuracy: 0.5951 - val_loss: 0.8630\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5762 - loss: 0.8901 - val_accuracy: 0.6214 - val_loss: 0.8271\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6269 - loss: 0.8062 - val_accuracy: 0.6214 - val_loss: 0.8156\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6631 - loss: 0.7498 - val_accuracy: 0.6373 - val_loss: 0.8287\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6816 - loss: 0.7003 - val_accuracy: 0.6232 - val_loss: 0.8650\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6995 - loss: 0.6535 - val_accuracy: 0.6270 - val_loss: 0.9384\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7061 - loss: 0.6302 - val_accuracy: 0.6364 - val_loss: 0.9826\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7449 - loss: 0.5808 - val_accuracy: 0.6429 - val_loss: 0.9766\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7468 - loss: 0.5765 - val_accuracy: 0.6186 - val_loss: 1.0637\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7534 - loss: 0.5508 - val_accuracy: 0.6054 - val_loss: 1.1600\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7548 - loss: 0.5474 - val_accuracy: 0.6261 - val_loss: 1.1002\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7655 - loss: 0.5445 - val_accuracy: 0.5951 - val_loss: 1.1292\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7715 - loss: 0.5222 - val_accuracy: 0.6054 - val_loss: 1.1276\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7787 - loss: 0.5002 - val_accuracy: 0.6298 - val_loss: 1.1270\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8102 - loss: 0.4539 - val_accuracy: 0.6223 - val_loss: 1.2952\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8505 - loss: 0.3737 - val_accuracy: 0.6298 - val_loss: 1.3539\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8515 - loss: 0.3513 - val_accuracy: 0.6111 - val_loss: 1.5008\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8632 - loss: 0.3375 - val_accuracy: 0.6214 - val_loss: 1.4472\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8542 - loss: 0.3500 - val_accuracy: 0.6036 - val_loss: 1.5515\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8638 - loss: 0.3215 - val_accuracy: 0.6139 - val_loss: 1.7735\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26955220103263855, 0.895900309085846]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27\n",
      "Train compile_metrics: 89.59%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.753150224685669, 0.6138706803321838]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.75\n",
      "Test compile_metrics: 61.39%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's send two inputs to the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82254842,  0.69215829],\n",
       "       [ 0.55146572,  0.15729058],\n",
       "       [ 0.07311286, -1.97951247],\n",
       "       ...,\n",
       "       [-0.61093878, -0.07631528],\n",
       "       [ 1.17819153, -0.94575177],\n",
       "       [-0.33618088,  1.03587419]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first two columns: longitude and latitude\n",
    "#(WHY: because lat and lon are good and important predictors)\n",
    "\n",
    "train_lon_lat = train_x[:,:2] # take only 2 out of 67 ---> The two rows are lat, longi together gives location\n",
    "\n",
    "# there fore we only to hidden layer 3 so as to find target as location\n",
    "\n",
    "train_lon_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lon_lat = test_x[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "input1 = keras.layers.Input(shape=(2,))\n",
    "input2 = keras.layers.Input(shape=(67,))\n",
    "\n",
    "hidden1 = keras.layers.Dense(67, activation='relu')(input2)\n",
    "hidden2 = keras.layers.Dense(67, activation='relu')(hidden1)\n",
    "hidden3 = keras.layers.Dense(67, activation='relu')(hidden2)\n",
    "\n",
    "concat = keras.layers.Concatenate()([input1, hidden3])\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n",
    "output = keras.layers.Dense(4, activation='softmax')(concat)\n",
    "\n",
    "model = keras.Model(inputs =[input1, input2], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.4684 - loss: 1.1340 - val_accuracy: 0.5829 - val_loss: 0.8690\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5699 - loss: 0.9028 - val_accuracy: 0.6420 - val_loss: 0.8151\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6060 - loss: 0.8383 - val_accuracy: 0.6223 - val_loss: 0.8273\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6425 - loss: 0.7928 - val_accuracy: 0.6092 - val_loss: 0.8597\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6535 - loss: 0.7640 - val_accuracy: 0.6214 - val_loss: 0.8973\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6717 - loss: 0.7299 - val_accuracy: 0.6270 - val_loss: 0.8641\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7176 - loss: 0.6618 - val_accuracy: 0.6364 - val_loss: 0.9032\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7398 - loss: 0.5958 - val_accuracy: 0.6298 - val_loss: 0.9329\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7700 - loss: 0.5414 - val_accuracy: 0.6082 - val_loss: 1.0490\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7748 - loss: 0.5396 - val_accuracy: 0.6129 - val_loss: 1.0875\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7930 - loss: 0.4876 - val_accuracy: 0.6073 - val_loss: 1.1417\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7899 - loss: 0.4850 - val_accuracy: 0.6017 - val_loss: 1.2696\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8035 - loss: 0.4830 - val_accuracy: 0.6073 - val_loss: 1.2337\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8168 - loss: 0.4481 - val_accuracy: 0.6007 - val_loss: 1.3577\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8025 - loss: 0.4559 - val_accuracy: 0.5979 - val_loss: 1.2815\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8327 - loss: 0.4195 - val_accuracy: 0.5961 - val_loss: 1.2837\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8386 - loss: 0.3917 - val_accuracy: 0.5726 - val_loss: 1.3948\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8631 - loss: 0.3250 - val_accuracy: 0.5886 - val_loss: 1.4640\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8945 - loss: 0.2661 - val_accuracy: 0.5961 - val_loss: 1.5623\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9055 - loss: 0.2361 - val_accuracy: 0.5886 - val_loss: 1.7381\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit((train_lon_lat, train_x), train_y, \n",
    "                    validation_data=((test_lon_lat, test_x), test_y), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25551721453666687, 0.903938889503479]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate((train_lon_lat, train_x), train_y, verbose=0)\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.26\n",
      "Train compile_metrics: 90.39%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7355337142944336, 0.5885660648345947]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate((test_lon_lat, test_x), test_y, verbose=0)\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.74\n",
      "Test compile_metrics: 58.86%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers, Learning rate, Dropout, Initialization & Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "\n",
    "#Set the learning rate:\n",
    "lr=0.01\n",
    "\n",
    "\n",
    "#Available optimizers:\n",
    "adafactor = keras.optimizers.Adafactor(learning_rate=lr)\n",
    "adam = keras.optimizers.Adam(learning_rate=lr)\n",
    "adamw = keras.optimizers.AdamW(learning_rate=lr)\n",
    "lion = keras.optimizers.Lion(learning_rate=lr)\n",
    "\n",
    "#Initializations:\n",
    "xavier = keras.initializers.GlorotNormal(seed=123)\n",
    "he = keras.initializers.HeNormal(seed=234)\n",
    "lecun = keras.initializers.LecunNormal(seed=345)\n",
    "\n",
    "\n",
    "# Activation functions. Uncomment only one\n",
    "elu = 'elu' \n",
    "relu = 'relu'\n",
    "tanh = 'tanh'\n",
    "sigmoid = 'sigmoid'\n",
    "selu = 'selu'\n",
    "gelu = 'gelu'\n",
    "\n",
    "\n",
    "\n",
    "#See the droput layers below:\n",
    "input1 = keras.layers.Input(shape=(67,))\n",
    "\n",
    "hidden1 = keras.layers.Dense(67, activation=elu, kernel_initializer=xavier)(input1)\n",
    "drop1   = keras.layers.Dropout(0.2)(hidden1)\n",
    "hidden2 = keras.layers.Dense(67, activation=relu, kernel_initializer=he)(drop1)\n",
    "drop2   = keras.layers.Dropout(0.2)(hidden2)\n",
    "hidden3 = keras.layers.Dense(67, activation=gelu, kernel_initializer=lecun)(drop2)\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n",
    "output = keras.layers.Dense(4, activation='softmax')(hidden3)\n",
    "\n",
    "#Compile\"\n",
    "model = keras.Model(inputs = input1, outputs = output)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.4353 - loss: 1.1902 - val_accuracy: 0.6017 - val_loss: 0.8650\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5427 - loss: 0.9666 - val_accuracy: 0.6186 - val_loss: 0.8397\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5780 - loss: 0.9172 - val_accuracy: 0.6186 - val_loss: 0.8327\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6045 - loss: 0.8756 - val_accuracy: 0.6270 - val_loss: 0.8163\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6090 - loss: 0.8567 - val_accuracy: 0.6382 - val_loss: 0.8082\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6096 - loss: 0.8328 - val_accuracy: 0.6382 - val_loss: 0.8170\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6140 - loss: 0.8310 - val_accuracy: 0.6354 - val_loss: 0.8087\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6234 - loss: 0.8013 - val_accuracy: 0.6223 - val_loss: 0.8401\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6154 - loss: 0.8190 - val_accuracy: 0.6382 - val_loss: 0.8257\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6392 - loss: 0.7720 - val_accuracy: 0.6232 - val_loss: 0.8209\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6512 - loss: 0.7669 - val_accuracy: 0.6467 - val_loss: 0.8084\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6675 - loss: 0.7415 - val_accuracy: 0.6242 - val_loss: 0.8199\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6630 - loss: 0.7467 - val_accuracy: 0.6298 - val_loss: 0.8244\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6421 - loss: 0.7613 - val_accuracy: 0.6232 - val_loss: 0.8650\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6689 - loss: 0.7292 - val_accuracy: 0.6214 - val_loss: 0.8546\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6655 - loss: 0.7247 - val_accuracy: 0.6261 - val_loss: 0.8403\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6623 - loss: 0.7283 - val_accuracy: 0.6092 - val_loss: 0.8749\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6697 - loss: 0.7269 - val_accuracy: 0.6120 - val_loss: 0.8807\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6734 - loss: 0.7313 - val_accuracy: 0.6242 - val_loss: 0.8699\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6749 - loss: 0.6987 - val_accuracy: 0.6092 - val_loss: 0.8613\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5812166929244995, 0.75]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.58\n",
      "Train compile_metrics: 75.00%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.852786123752594, 0.6091846227645874]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.85\n",
      "Test compile_metrics: 60.92%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping based on validation results\n",
    "\n",
    "To do this, you need to send the validation data sets to the fit() function and use a callback.\n",
    "\n",
    "EarlyStopping Arguments:\n",
    "\n",
    "**monitor:** quantity to be monitored.<br>\n",
    "**min_delta:** minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.<br>\n",
    "**patience:** number of epochs with no improvement after which training will be stopped.<br>\n",
    "**verbose:** verbosity mode.<br>\n",
    "**mode:** one of {auto, min, max}. In min mode, training will stop when the quantity monitored has stopped decreasing; in max mode it will stop when the quantity monitored has stopped increasing; in auto mode, the direction is automatically inferred from the name of the monitored quantity.<br>\n",
    "**baseline:** Baseline value for the monitored quantity to reach. Training will stop if the model doesn't show improvement over the baseline.<br>\n",
    "**restore_best_weights:** whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(67,)))\n",
    "model.add(keras.layers.Dense(67, activation='relu'))\n",
    "model.add(keras.layers.Dense(67, activation='relu'))\n",
    "model.add(keras.layers.Dense(67, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.3788 - loss: 1.3106 - val_accuracy: 0.5267 - val_loss: 1.0840\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5269 - loss: 1.0536 - val_accuracy: 0.6064 - val_loss: 0.9075\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5691 - loss: 0.9418 - val_accuracy: 0.6270 - val_loss: 0.8601\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6069 - loss: 0.8874 - val_accuracy: 0.6392 - val_loss: 0.8330\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6271 - loss: 0.8464 - val_accuracy: 0.6495 - val_loss: 0.8140\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6445 - loss: 0.8145 - val_accuracy: 0.6495 - val_loss: 0.8024\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6619 - loss: 0.7883 - val_accuracy: 0.6598 - val_loss: 0.7944\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6709 - loss: 0.7660 - val_accuracy: 0.6654 - val_loss: 0.7894\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6741 - loss: 0.7464 - val_accuracy: 0.6682 - val_loss: 0.7868\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6870 - loss: 0.7275 - val_accuracy: 0.6692 - val_loss: 0.7852\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6985 - loss: 0.7093 - val_accuracy: 0.6645 - val_loss: 0.7843\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7075 - loss: 0.6917 - val_accuracy: 0.6645 - val_loss: 0.7840\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7172 - loss: 0.6740 - val_accuracy: 0.6635 - val_loss: 0.7854\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7179 - loss: 0.6562 - val_accuracy: 0.6617 - val_loss: 0.7872\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7247 - loss: 0.6387 - val_accuracy: 0.6617 - val_loss: 0.7909\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7370 - loss: 0.6211 - val_accuracy: 0.6607 - val_loss: 0.7952\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7442 - loss: 0.6041 - val_accuracy: 0.6560 - val_loss: 0.8012\n",
      "Epoch 17: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x191e13e5ed0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]\n",
    "\n",
    "model.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "          epochs=100, batch_size=100, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5758649110794067, 0.7656752467155457]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.58\n",
      "Train compile_metrics: 76.57%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7924169898033142, 0.6560449600219727]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.79\n",
      "Test compile_metrics: 65.60%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL: Grid Search using Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Obtaining dependency information for keras-tuner from https://files.pythonhosted.org/packages/db/5d/945296512980b0827e93418514c8be9236baa6f0a1e8ca8be3a2026665b0/keras_tuner-1.4.7-py3-none-any.whl.metadata\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras-tuner) (3.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras-tuner) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Obtaining dependency information for kt-legacy from https://files.pythonhosted.org/packages/16/53/aca9f36da2516db008017db85a1f3cafaee0efc5fc7a25d94c909651792f/kt_legacy-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: rich in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: optree in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.10.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\mural\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from optree->keras->keras-tuner) (4.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.1 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 92.2/129.1 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 129.1/129.1 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "# If you don't have Keras Tuner installed, you need to convert this cell to \"code\" and execute it.\n",
    "\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    n_hidden = params.Int(\"n_hidden\", min_value=0, max_value=10, default=2)\n",
    "    n_neurons = params.Int(\"n_neurons\", min_value=50, max_value=100)\n",
    "    learning_rate = params.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\") #1e-4 applied funcn which is 0.00001\n",
    "    optimizer = params.Choice(\"optimizer\", values=[\"adamw\", \"adam\", \"adafactor\", \"lion\"])\n",
    "    \n",
    "    if optimizer==\"adamw\":\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate)\n",
    "    elif optimizer==\"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer==\"adafactor\":\n",
    "        optimizer = tf.keras.optimizers.Adafactor(learning_rate=learning_rate)\n",
    "    elif optimizer==\"lion\":\n",
    "        optimizer = tf.keras.optimizers.Lion(learning_rate=learning_rate)\n",
    "\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(67,)))\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 10s]\n",
      "val_accuracy: 0.6316776275634766\n",
      "\n",
      "Best val_accuracy So Far: 0.6344892382621765\n",
      "Total elapsed time: 00h 00m 57s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(build_model, objective=\"val_accuracy\", max_trials=5, seed=42, overwrite=True)\n",
    "\n",
    "random_search_tuner.search(train_x, train_y, epochs=5, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mural\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = random_search_tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 9,\n",
       " 'n_neurons': 67,\n",
       " 'learning_rate': 0.0012482904754698163,\n",
       " 'optimizer': 'adamw'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = best_model.evaluate(train_x, train_y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.74\n",
      "Train compile_metrics: 67.32%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {best_model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {best_model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = best_model.evaluate(test_x, test_y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.83\n",
      "Test compile_metrics: 63.45%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {best_model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {best_model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperband Search (to iteratively converge on a good performing model)\n",
    "\n",
    "From the TensorFlow documentation: The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + $log_{factor}$(max_epochs) and rounding it up to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 12s]\n",
      "val_accuracy: 0.6138706803321838\n",
      "\n",
      "Best val_accuracy So Far: 0.6241799592971802\n",
      "Total elapsed time: 00h 01m 17s\n"
     ]
    }
   ],
   "source": [
    "hyperband_tuner = kt.Hyperband(build_model, objective='val_accuracy', max_epochs=5, factor=3,  overwrite=True)\n",
    "\n",
    "hyperband_tuner.search(train_x, train_y, epochs=5, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = hyperband_tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 5,\n",
       " 'n_neurons': 52,\n",
       " 'learning_rate': 0.0006075730939147763,\n",
       " 'optimizer': 'adam',\n",
       " 'tuner/epochs': 5,\n",
       " 'tuner/initial_epoch': 2,\n",
       " 'tuner/bracket': 1,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0001'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperband_tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = best_model.evaluate(train_x, train_y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.81\n",
      "Train compile_metrics: 64.11%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Train {best_model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Train {best_model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = best_model.evaluate(test_x, test_y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.82\n",
      "Test compile_metrics: 62.42%\n"
     ]
    }
   ],
   "source": [
    "# Print the values\n",
    "\n",
    "print(f\"Test {best_model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "\n",
    "print(f\"Test {best_model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
