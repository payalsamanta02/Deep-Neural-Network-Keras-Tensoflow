{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - KERAS DNN Regression\n",
    "\n",
    "We will predict the price of an AIRBNB listing (`price` column). This is a regression task.\n",
    "\n",
    "**The unit of analysis is an AIRBNB LISTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>price_per_extra_person</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_days_btw_first_last_review</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>price</th>\n",
       "      <th>price_gte_150</th>\n",
       "      <th>price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.282619</td>\n",
       "      <td>-71.133068</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moderate</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.286241</td>\n",
       "      <td>-71.134374</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>804</td>\n",
       "      <td>94.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_$75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.292438</td>\n",
       "      <td>-71.135765</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>2574</td>\n",
       "      <td>98.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_$75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.281106</td>\n",
       "      <td>-71.121021</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_$75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.284512</td>\n",
       "      <td>-71.136258</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>380</td>\n",
       "      <td>99.0</td>\n",
       "      <td>flexible</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>btw_$75-$150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_is_superhost  host_identity_verified neighbourhood_cleansed  \\\n",
       "0                  0                       0             Roslindale   \n",
       "1                  0                       1             Roslindale   \n",
       "2                  1                       1             Roslindale   \n",
       "3                  0                       0             Roslindale   \n",
       "4                  1                       1             Roslindale   \n",
       "\n",
       "    latitude  longitude property_type        room_type  accommodates  \\\n",
       "0  42.282619 -71.133068         House  Entire home/apt             4   \n",
       "1  42.286241 -71.134374     Apartment     Private room             2   \n",
       "2  42.292438 -71.135765     Apartment     Private room             2   \n",
       "3  42.281106 -71.121021         House     Private room             4   \n",
       "4  42.284512 -71.136258         House     Private room             2   \n",
       "\n",
       "   bathrooms  bedrooms  ...  guests_included price_per_extra_person  \\\n",
       "0        1.5       2.0  ...                1                      0   \n",
       "1        1.0       1.0  ...                0                      0   \n",
       "2        1.0       1.0  ...                1                     20   \n",
       "3        1.0       1.0  ...                2                     25   \n",
       "4        1.5       1.0  ...                1                      0   \n",
       "\n",
       "   minimum_nights  number_of_reviews  number_days_btw_first_last_review  \\\n",
       "0               2                  0                                  0   \n",
       "1               2                 36                                804   \n",
       "2               3                 41                               2574   \n",
       "3               1                  1                                  0   \n",
       "4               2                 29                                380   \n",
       "\n",
       "   review_scores_rating  cancellation_policy  price  price_gte_150  \\\n",
       "0                   NaN             moderate    250              1   \n",
       "1                  94.0             moderate     65              0   \n",
       "2                  98.0             moderate     65              0   \n",
       "3                 100.0             moderate     75              0   \n",
       "4                  99.0             flexible     79              0   \n",
       "\n",
       "  price_category  \n",
       "0        gte_226  \n",
       "1        lte_$75  \n",
       "2        lte_$75  \n",
       "3        lte_$75  \n",
       "4   btw_$75-$150  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb = pd.read_csv(\"airbnb.csv\")\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(airbnb, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be careful: we haven't seperated the target column yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the variables we can't use in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't use the following columns in this tutorial\n",
    "\n",
    "train = train_set.drop(['price_category', 'price_gte_150'], axis=1)\n",
    "test = test_set.drop(['price_category', 'price_gte_150'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable (we don't want to transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train[['price']]\n",
    "test_target = test[['price']]\n",
    "\n",
    "train_inputs = train.drop(['price'], axis=1)\n",
    "test_inputs = test.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Let's derive a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember, the \"minimum_nights\" column is highly skewed. Let's try to transform it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      1017\n",
       "2       666\n",
       "3       443\n",
       "4        88\n",
       "7        82\n",
       "5        58\n",
       "10       45\n",
       "30       18\n",
       "14       16\n",
       "15       14\n",
       "6        12\n",
       "28        6\n",
       "20        5\n",
       "32        3\n",
       "60        3\n",
       "9         2\n",
       "18        1\n",
       "13        1\n",
       "8         1\n",
       "273       1\n",
       "11        1\n",
       "21        1\n",
       "90        1\n",
       "23        1\n",
       "17        1\n",
       "25        1\n",
       "Name: minimum_nights, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs['minimum_nights'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_inputs['minimum_nights'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import power transformer from sklearn. It will help us create a \"normal distribution\"\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "QT = QuantileTransformer(output_distribution='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_min_nights = QT.fit_transform(train_inputs[['minimum_nights']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': '0'}>]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_min_nights).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE1: We didn't make the transformed variable as part of the input variables yet. To do that, we will use the pipeline.\n",
    "\n",
    "NOTE2: We don't need to create a function (like before). This transformer already has fit() and transform(). So, we can use this in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_is_superhost                      int64\n",
       "host_identity_verified                 int64\n",
       "neighbourhood_cleansed                object\n",
       "latitude                             float64\n",
       "longitude                            float64\n",
       "property_type                         object\n",
       "room_type                             object\n",
       "accommodates                           int64\n",
       "bathrooms                            float64\n",
       "bedrooms                             float64\n",
       "beds                                 float64\n",
       "bed_type                              object\n",
       "Number of amenities                    int64\n",
       "guests_included                        int64\n",
       "price_per_extra_person                 int64\n",
       "minimum_nights                         int64\n",
       "number_of_reviews                      int64\n",
       "number_days_btw_first_last_review      int64\n",
       "review_scores_rating                 float64\n",
       "cancellation_policy                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this stage, you can manually identify numeric, binary, and categorical columns as follows:**\n",
    "\n",
    "`numeric_columns = ['latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'Number of amenities', 'guests_included', 'price_per_extra_person', 'minimum_nights', 'number_of_reviews', 'number_days_btw_first_last_review', 'review_scores_rating']`\n",
    " \n",
    " `binary_columns = ['host_is_superhost', 'host_identity_verified']`\n",
    " \n",
    " `categorical_columns = ['neighbourhood_cleansed', 'property_type', 'room_type', 'bed_type', 'cancellation_policy']`\n",
    " \n",
    "<br>\n",
    " \n",
    "**If you do not want to manually type these, you can do the below tricks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['host_is_superhost', 'host_identity_verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost', 'host_identity_verified']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'Number of amenities',\n",
       " 'guests_included',\n",
       " 'price_per_extra_person',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'number_days_btw_first_last_review',\n",
       " 'review_scores_rating']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neighbourhood_cleansed',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'bed_type',\n",
       " 'cancellation_policy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = ['minimum_nights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_column = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('quantiletransformer', QuantileTransformer(output_distribution='uniform'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns),\n",
    "        ('trans', my_new_column, transformed_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82254842,  0.69215829,  0.54753414, ...,  1.        ,\n",
       "         1.        ,  0.54254254],\n",
       "       [ 0.55146572,  0.15729058,  0.54753414, ...,  0.        ,\n",
       "         1.        ,  0.54254254],\n",
       "       [ 0.07311286, -1.97951247, -0.59100739, ...,  0.        ,\n",
       "         0.        ,  0.9019019 ],\n",
       "       ...,\n",
       "       [-0.61093878, -0.07631528,  3.96315871, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.17819153, -0.94575177, -1.16027815, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.33618088,  1.03587419, -0.59100739, ...,  0.        ,\n",
       "         1.        ,  0.54254254]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488, 67)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.21269719, -1.20324989,  0.54753414, ...,  0.        ,\n",
       "         1.        ,  0.54254254],\n",
       "       [-2.86419979, -2.67831359, -0.59100739, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.11443035,  1.26295963, -0.59100739, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.47803436, -1.63486781, -0.59100739, ...,  1.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.59928397,  0.34795157,  2.82461719, ...,  0.        ,\n",
       "         0.        ,  0.54254254],\n",
       "       [ 0.19953968,  0.22845713, -0.59100739, ...,  0.        ,\n",
       "         1.        ,  0.93443443]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067, 67)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No transformation needed for the target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "dummy_regr.fit(train_x, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train RMSE: 103.84299127618122\n"
     ]
    }
   ],
   "source": [
    "#Baseline Train RMSE\n",
    "dummy_train_pred = dummy_regr.predict(train_x)\n",
    "\n",
    "baseline_train_mse = mean_squared_error(train_target, dummy_train_pred)\n",
    "\n",
    "baseline_train_rmse = np.sqrt(baseline_train_mse)\n",
    "\n",
    "print('Baseline Train RMSE: {}' .format(baseline_train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test RMSE: 102.31125032666752\n"
     ]
    }
   ],
   "source": [
    "#Baseline Test RMSE\n",
    "dummy_test_pred = dummy_regr.predict(test_x)\n",
    "\n",
    "baseline_test_mse = mean_squared_error (test_target, dummy_test_pred)\n",
    "\n",
    "baseline_test_rmse = np.sqrt(baseline_test_mse)\n",
    "\n",
    "print('Baseline Test RMSE: {}' .format(baseline_test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488, 67)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is your input shape?\n",
    "#(meaning: how many neurons should be in the input layer?)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer (Shallow) Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(67,)))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation=None))\n",
    "\n",
    "#final layer: there has to be 1 node with no activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal target (as in this example):\n",
    "\n",
    "Final layer's activation = **softmax** <br>\n",
    "loss = **sparse_categorical_crossentropy**\n",
    "\n",
    "## One-hot target\n",
    "\n",
    "Final layer's activation = **softmax** <br>\n",
    "loss = **categorical_crossentropy**\n",
    "\n",
    "## Binary target \n",
    "\n",
    "Final layer has only 1 neuron <br>\n",
    "Final layer's activation = **sigmoid** <br>\n",
    "loss = **binary_crossentropy**\n",
    "\n",
    "## Regression task (target is continuous)\n",
    "\n",
    "Final layer has only 1 neuron (keras.layers.Dense(1))<br>\n",
    "Activation is None<br>\n",
    "loss = **mean_squared_error**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 39151.1211 - mse: 39157.2695 - val_loss: 27791.9238 - val_mse: 28069.9883\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27977.5234 - mse: 27983.3984 - val_loss: 11745.3477 - val_mse: 11900.6572\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11408.8633 - mse: 11410.3799 - val_loss: 5427.8442 - val_mse: 5501.1807\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6091.6855 - mse: 6092.1670 - val_loss: 4835.1543 - val_mse: 4896.9219\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5433.7764 - mse: 5434.2920 - val_loss: 4438.1963 - val_mse: 4496.1704\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5097.6323 - mse: 5098.0464 - val_loss: 4237.6782 - val_mse: 4290.8433\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4833.6846 - mse: 4834.0620 - val_loss: 4082.4514 - val_mse: 4132.5713\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4658.7920 - mse: 4659.1255 - val_loss: 3977.0203 - val_mse: 4024.1416\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4524.5703 - mse: 4524.8687 - val_loss: 3899.0688 - val_mse: 3943.6477\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4423.5942 - mse: 4423.8647 - val_loss: 3839.5078 - val_mse: 3881.7886\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4343.2646 - mse: 4343.5117 - val_loss: 3790.5447 - val_mse: 3830.8169\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4276.0464 - mse: 4276.2725 - val_loss: 3750.7312 - val_mse: 3789.1821\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4216.4204 - mse: 4216.6328 - val_loss: 3714.7771 - val_mse: 3751.4495\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4162.9434 - mse: 4163.1440 - val_loss: 3685.3577 - val_mse: 3720.5381\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4112.5117 - mse: 4112.7046 - val_loss: 3660.5562 - val_mse: 3694.4163\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4064.7563 - mse: 4064.9456 - val_loss: 3638.5732 - val_mse: 3671.3069\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4022.9509 - mse: 4023.1316 - val_loss: 3622.5452 - val_mse: 3654.3979\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3982.1423 - mse: 3982.3220 - val_loss: 3607.4404 - val_mse: 3638.6030\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3947.5603 - mse: 3947.7402 - val_loss: 3596.3206 - val_mse: 3626.8650\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3915.3970 - mse: 3915.5762 - val_loss: 3587.3352 - val_mse: 3617.3081\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_target, \n",
    "                    validation_data=(test_x, test_target), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_target, verbose=0)\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_target, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "compile_metrics: 3620.60\n",
      "RMSE: 60.17\n"
     ]
    }
   ],
   "source": [
    "# extract the TRAIN mse from model.evaluate\n",
    "\n",
    "print(\"TRAIN:\")\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], train_scores[1]))\n",
    "\n",
    "#Calculate RMSE:\n",
    "print(\"%s: %.2f\" % (\"RMSE\", np.sqrt(train_scores[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:\n",
      "compile_metrics: 3617.31\n",
      "RMSE: 60.14\n"
     ]
    }
   ],
   "source": [
    "# extract the TEST mse from model.evaluate\n",
    "\n",
    "print(\"TEST:\")\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], test_scores[1]))\n",
    "\n",
    "#Calculate RMSE:\n",
    "print(\"%s: %.2f\" % (\"RMSE\", np.sqrt(test_scores[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDK if the model above is underfitting lets use below wide and deep what values they produce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Network (Funnel architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(67,)))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation=None))\n",
    "\n",
    "\n",
    "#final layer: there has to be 1 node with no activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 37497.5469 - mse: 37506.9023 - val_loss: 6000.1934 - val_mse: 6078.4844\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7725.2500 - mse: 7726.4487 - val_loss: 4337.5737 - val_mse: 4392.1260\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4980.1641 - mse: 4980.6875 - val_loss: 3881.8813 - val_mse: 3930.0088\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4494.3535 - mse: 4494.6890 - val_loss: 3748.7256 - val_mse: 3789.1345\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4298.1079 - mse: 4298.3838 - val_loss: 3686.6116 - val_mse: 3723.4517\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4184.6328 - mse: 4184.8643 - val_loss: 3645.9922 - val_mse: 3680.2429\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4099.2080 - mse: 4099.4189 - val_loss: 3615.6482 - val_mse: 3648.4797\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4024.3560 - mse: 4024.5571 - val_loss: 3597.0881 - val_mse: 3628.7954\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3956.0029 - mse: 3956.2017 - val_loss: 3581.0706 - val_mse: 3612.0508\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3891.5896 - mse: 3891.7961 - val_loss: 3579.0728 - val_mse: 3609.4231\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3834.9160 - mse: 3835.1228 - val_loss: 3576.3289 - val_mse: 3606.6321\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3776.8083 - mse: 3777.0276 - val_loss: 3579.5615 - val_mse: 3609.8311\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3720.1042 - mse: 3720.3369 - val_loss: 3589.5227 - val_mse: 3619.7412\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3674.8010 - mse: 3675.0349 - val_loss: 3600.3743 - val_mse: 3629.9768\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3626.0579 - mse: 3626.3062 - val_loss: 3600.5374 - val_mse: 3630.1562\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3587.3496 - mse: 3587.6123 - val_loss: 3610.7788 - val_mse: 3640.5964\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3552.0447 - mse: 3552.3171 - val_loss: 3626.7268 - val_mse: 3656.7649\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3505.6260 - mse: 3505.8831 - val_loss: 3607.7195 - val_mse: 3635.9832\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3453.2378 - mse: 3453.5081 - val_loss: 3624.5662 - val_mse: 3652.2742\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3417.3005 - mse: 3417.5696 - val_loss: 3638.3875 - val_mse: 3665.0720\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_target, \n",
    "                    validation_data=(test_x, test_target), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_target, verbose=0)\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_target, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "compile_metrics: 3059.76\n",
      "RMSE: 55.32\n"
     ]
    }
   ],
   "source": [
    "# extract the TRAIN mse from model.evaluate\n",
    "\n",
    "print(\"TRAIN:\")\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], train_scores[1]))\n",
    "\n",
    "#Calculate RMSE:\n",
    "print(\"%s: %.2f\" % (\"RMSE\", np.sqrt(train_scores[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:\n",
      "compile_metrics: 3665.07\n",
      "RMSE: 60.54\n"
     ]
    }
   ],
   "source": [
    "# extract the TEST mse from model.evaluate\n",
    "\n",
    "print(\"TEST:\")\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], test_scores[1]))\n",
    "\n",
    "#Calculate RMSE:\n",
    "print(\"%s: %.2f\" % (\"RMSE\", np.sqrt(test_scores[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide & Deep Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's send all inputs to the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "\n",
    "inputlayer = keras.layers.Input(shape=(67,))\n",
    "\n",
    "hidden1 = keras.layers.Dense(67, activation='relu')(inputlayer)\n",
    "hidden2 = keras.layers.Dense(67, activation='relu')(hidden1)\n",
    "hidden3 = keras.layers.Dense(67, activation='relu')(hidden2)\n",
    "\n",
    "concat = keras.layers.Concatenate()([inputlayer, hidden3])\n",
    "\n",
    "#final layer: there has to be 1 node with no activation\n",
    "output = keras.layers.Dense(1, activation=None)(concat)\n",
    "\n",
    "model = keras.Model(inputs =[inputlayer], outputs = output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_5       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,556</span> â”‚ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,556</span> â”‚ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,556</span> â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">134</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_5       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        â”‚      \u001b[38;5;34m4,556\u001b[0m â”‚ input_layer_5[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        â”‚      \u001b[38;5;34m4,556\u001b[0m â”‚ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        â”‚      \u001b[38;5;34m4,556\u001b[0m â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m134\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_5[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚        \u001b[38;5;34m135\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,803</span> (53.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,803\u001b[0m (53.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,803</span> (53.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,803\u001b[0m (53.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 30119.7461 - mse: 30125.5547 - val_loss: 5800.7300 - val_mse: 5881.7754\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5755.3276 - mse: 5755.6777 - val_loss: 3924.0076 - val_mse: 3974.0544\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4627.7847 - mse: 4628.0171 - val_loss: 3735.2927 - val_mse: 3777.1067\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4281.2095 - mse: 4281.4873 - val_loss: 3710.0029 - val_mse: 3753.0015\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4277.7256 - mse: 4278.0737 - val_loss: 3727.5674 - val_mse: 3771.1582\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4273.8467 - mse: 4274.2739 - val_loss: 3777.6360 - val_mse: 3822.8162\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4251.8906 - mse: 4252.3779 - val_loss: 3832.9937 - val_mse: 3880.1201\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4218.3618 - mse: 4218.8838 - val_loss: 3872.4104 - val_mse: 3920.2659\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4155.4214 - mse: 4155.9663 - val_loss: 3892.7373 - val_mse: 3941.8462\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4076.3354 - mse: 4076.8870 - val_loss: 3904.1150 - val_mse: 3953.5356\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3991.3767 - mse: 3991.9285 - val_loss: 3895.0352 - val_mse: 3943.9390\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3887.4915 - mse: 3888.0476 - val_loss: 3873.6689 - val_mse: 3922.7866\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3780.9116 - mse: 3781.4597 - val_loss: 3866.9968 - val_mse: 3915.7178\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3663.5676 - mse: 3664.0842 - val_loss: 3780.4343 - val_mse: 3826.1870\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3512.5120 - mse: 3513.0061 - val_loss: 3789.5515 - val_mse: 3834.8176\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3436.2537 - mse: 3436.7449 - val_loss: 3798.2126 - val_mse: 3843.4121\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3329.5422 - mse: 3330.0112 - val_loss: 3805.5649 - val_mse: 3849.7195\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3232.2407 - mse: 3232.7046 - val_loss: 3802.8604 - val_mse: 3846.0923\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3154.8738 - mse: 3155.3276 - val_loss: 3851.0366 - val_mse: 3894.7249\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3080.1624 - mse: 3080.5925 - val_loss: 3863.8696 - val_mse: 3907.0059\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_target, \n",
    "                    validation_data=(test_x, test_target), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_target, verbose=0)\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_target, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "compile_metrics: 2778.57\n",
      "RMSE: 52.71\n"
     ]
    }
   ],
   "source": [
    "# extract the TRAIN mse from model.evaluate\n",
    "\n",
    "print(\"TRAIN:\")\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], train_scores[1]))\n",
    "\n",
    "#Calculate RMSE:\n",
    "print(\"%s: %.2f\" % (\"RMSE\", np.sqrt(train_scores[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:\n",
      "compile_metrics: 3907.01\n",
      "RMSE: 62.51\n"
     ]
    }
   ],
   "source": [
    "# extract the TEST mse from model.evaluate\n",
    "\n",
    "print(\"TEST:\")\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], test_scores[1]))\n",
    "\n",
    "#Calculate RMSE:\n",
    "print(\"%s: %.2f\" % (\"RMSE\", np.sqrt(test_scores[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Grid Search using Keras Tuner"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If you don't have Keras Tuner installed, you need to convert this cell to \"code\" and execute it.\n",
    "\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    n_hidden = params.Int(\"n_hidden\", min_value=1, max_value=5, default=2)\n",
    "    n_neurons = params.Int(\"n_neurons\", min_value=50, max_value=60)\n",
    "    learning_rate = params.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    optimizer = params.Choice(\"optimizer\", values=[\"adam\", \"adamw\"])\n",
    "    \n",
    "    if optimizer==\"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer==\"adamw\":\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate)\n",
    "\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(67,)))\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 07s]\n",
      "val_mse: 4485.92919921875\n",
      "\n",
      "Best val_mse So Far: 3803.283447265625\n",
      "Total elapsed time: 00h 00m 39s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(build_model, objective=\"val_mse\", max_trials=5, seed=42, overwrite=True)\n",
    "\n",
    "random_search_tuner.search(train_x, train_target, epochs=5, validation_data=(test_x, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mural\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = random_search_tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 5,\n",
       " 'n_neurons': 53,\n",
       " 'learning_rate': 0.0012482904754698163,\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = best_model.evaluate(train_x, train_target, verbose=0)\n",
    "\n",
    "test_scores = best_model.evaluate(test_x, test_target, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSE: 62.89\n"
     ]
    }
   ],
   "source": [
    "# extract the TRAIN mse from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (\"TRAIN RMSE\", np.sqrt(train_scores[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RMSE: 61.67\n"
     ]
    }
   ],
   "source": [
    "# extract the TEST mse from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (\"TEST RMSE\", np.sqrt(test_scores[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperband Search (to iteratively converge on a good performing model)\n",
    "\n",
    "From the TensorFlow documentation: The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + $log_{factor}$(max_epochs) and rounding it up to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 08s]\n",
      "val_mse: 3891.29638671875\n",
      "\n",
      "Best val_mse So Far: 3795.8447265625\n",
      "Total elapsed time: 00h 00m 52s\n"
     ]
    }
   ],
   "source": [
    "hyperband_tuner = kt.Hyperband(build_model, objective='val_mse', max_epochs=5, factor=3,  overwrite=True)\n",
    "\n",
    "hyperband_tuner.search(train_x, train_target, epochs=5, validation_data=(test_x, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mural\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = hyperband_tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 3,\n",
       " 'n_neurons': 56,\n",
       " 'learning_rate': 0.005734429228475826,\n",
       " 'optimizer': 'adam',\n",
       " 'tuner/epochs': 5,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 0,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperband_tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = best_model.evaluate(train_x, train_target, verbose=0)\n",
    "\n",
    "test_scores = best_model.evaluate(test_x, test_target, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSE: 61.12\n"
     ]
    }
   ],
   "source": [
    "# extract the TRAIN mse from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (\"TRAIN RMSE\", np.sqrt(train_scores[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RMSE: 61.61\n"
     ]
    }
   ],
   "source": [
    "# extract the TEST mse from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (\"TEST RMSE\", np.sqrt(test_scores[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
